{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"%%bash\npip install nltk\npip install datasets\npip install transformers[torch]\npip install tokenizers\npip install evaluate\npip install rouge_score\npip install sentencepiece\npip install huggingface_hub","metadata":{"execution":{"iopub.status.busy":"2024-05-19T17:26:32.154131Z","iopub.execute_input":"2024-05-19T17:26:32.154989Z","iopub.status.idle":"2024-05-19T17:28:07.140955Z","shell.execute_reply.started":"2024-05-19T17:26:32.154957Z","shell.execute_reply":"2024-05-19T17:28:07.140147Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: transformers[torch] in /opt/conda/lib/python3.10/site-packages (4.39.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (3.13.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.22.2)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2023.12.25)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.31.0)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.4.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (4.66.1)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (2.1.2)\nRequirement already satisfied: accelerate>=0.21.0 in /opt/conda/lib/python3.10/site-packages (from transformers[torch]) (0.29.3)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.3)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2024.2.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers[torch]) (3.1.1)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->transformers[torch]) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers[torch]) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->transformers[torch]) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->transformers[torch]) (1.3.0)\nRequirement already satisfied: tokenizers in /opt/conda/lib/python3.10/site-packages (0.15.2)\nRequirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /opt/conda/lib/python3.10/site-packages (from tokenizers) (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub<1.0,>=0.16.4->tokenizers) (2024.2.2)\nCollecting evaluate\n  Downloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\nRequirement already satisfied: datasets>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.18.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from evaluate) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from evaluate) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.2.0)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from evaluate) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from evaluate) (21.3)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.13.1)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (0.6)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (3.9.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets>=2.0.0->evaluate) (6.0.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->evaluate) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->evaluate) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->evaluate) (2023.4)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.16.0)\nDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: evaluate\nSuccessfully installed evaluate-0.4.2\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.26.4)\nRequirement already satisfied: six>=1.14.0 in /opt/conda/lib/python3.10/site-packages (from rouge_score) (1.16.0)\nBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py): started\n  Building wheel for rouge_score (setup.py): finished with status 'done'\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=6f6863811f77a3eddf40977e77213b8b4ab7da74ec10e4b1c489cbae6046a3f6\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: rouge_score\nSuccessfully installed rouge_score-0.1.2\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (0.2.0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.22.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\nRequirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2024.2.0)\nRequirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\nRequirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.9->huggingface_hub) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"import nltk\nimport evaluate\nimport numpy as np\nfrom datasets import load_dataset\nfrom transformers import T5Tokenizer, DataCollatorForSeq2Seq\nfrom transformers import T5ForConditionalGeneration, Seq2SeqTrainingArguments, Seq2SeqTrainer","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-19T17:28:07.142692Z","iopub.execute_input":"2024-05-19T17:28:07.143111Z","iopub.status.idle":"2024-05-19T17:28:25.370882Z","shell.execute_reply.started":"2024-05-19T17:28:07.143079Z","shell.execute_reply":"2024-05-19T17:28:25.369816Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"2024-05-19 17:28:15.797303: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-05-19 17:28:15.797445: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-05-19 17:28:15.924245: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load the tokenizer, model, and data collator\nMODEL_NAME = \"google/flan-t5-small\"\n\ntokenizer = T5Tokenizer.from_pretrained(MODEL_NAME)\nmodel = T5ForConditionalGeneration.from_pretrained(MODEL_NAME)\ndata_collator = DataCollatorForSeq2Seq(tokenizer=tokenizer, model=model)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T17:28:25.372042Z","iopub.execute_input":"2024-05-19T17:28:25.372628Z","iopub.status.idle":"2024-05-19T17:28:32.018858Z","shell.execute_reply.started":"2024-05-19T17:28:25.372599Z","shell.execute_reply":"2024-05-19T17:28:32.017920Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/2.54k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"66e5493717d84ae49a9c237b8c1d9c9a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4a2e404007740f2a136aafeff8a70c4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/2.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7fc55ba4925a4f30aaa92cdcf783fc07"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/2.42M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"972d3e22bcb34b0aa42af707da18f51c"}},"metadata":{}},{"name":"stderr","text":"You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/1.40k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e030f21375a24e889c479f5fa024d3b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/308M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4aa5cdc051de42deb122ebe3906fdd61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5307e4902bf3402bad8a1b408acba303"}},"metadata":{}}]},{"cell_type":"code","source":"dataset = load_dataset(\"eli5_category\")\ndataset","metadata":{"execution":{"iopub.status.busy":"2024-05-19T17:28:32.021017Z","iopub.execute_input":"2024-05-19T17:28:32.021299Z","iopub.status.idle":"2024-05-19T17:29:05.748107Z","shell.execute_reply.started":"2024-05-19T17:28:32.021275Z","shell.execute_reply":"2024-05-19T17:29:05.747260Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for eli5_category contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/eli5_category\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.17k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac6a9ebb94e34eb48768b972922b3b46"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/12.6k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"962b2b71075b46a5808cbe64a53c435e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/62.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"86cd28f6bef049229a7350cfd26a743f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/5.00M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4af4efad03d427c8989a84408e77017"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.76M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"34d408025021446b8f39afc01a7e645c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.85M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58ba40f3a5fa46d8b128966fbf53d37b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/91772 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"527d4aeb98714fc3a755579c95536fbc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation1 split:   0%|          | 0/5446 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6c65cc8dee34725b2a95cb5120c87e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation2 split:   0%|          | 0/2375 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"262e2bf988594d81ad6a543d3d068e60"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/5411 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7479ef218ad34cd2a208f1a964302144"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n        num_rows: 91772\n    })\n    validation1: Dataset({\n        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n        num_rows: 5446\n    })\n    validation2: Dataset({\n        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n        num_rows: 2375\n    })\n    test: Dataset({\n        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n        num_rows: 5411\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def organize_dataset(data):\n    questions = []\n    answers_list = []\n    scores_list = []\n\n    for item in data:\n        answers = item['answers']['text']\n        scores = item['answers'].get('score', [])\n\n        questions.append(item['title'])\n        answers_list.append(answers)\n        scores_list.append(scores)\n    return {\n        \"questions\": questions,\n        \"answers\": answers_list,\n        \"scores\": scores_list\n    }\n\ntrain_data = organize_dataset(dataset[\"train\"])\nsmall_train_data = {key: value[:100] for key, value in train_data.items()}\nval_data = organize_dataset(dataset[\"validation1\"])\nsmall_val_data = {key: value[:100] for key, value in val_data.items()}\n","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:26:28.416882Z","iopub.execute_input":"2024-05-19T18:26:28.417266Z","iopub.status.idle":"2024-05-19T18:26:44.325579Z","shell.execute_reply.started":"2024-05-19T18:26:28.417238Z","shell.execute_reply":"2024-05-19T18:26:44.324289Z"},"trusted":true},"execution_count":44,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset, DatasetDict\ndef new_dataset(dataset):\n\n  questions = dataset['questions']\n\n  question_list = []\n  answer_list = []\n  for index, question in enumerate(questions):\n    scores = dataset['scores'][index]\n    percentile_50 =np.percentile(scores, 50)\n    for index1, score in enumerate(scores):\n      if score >=percentile_50:\n        question_list.append(question)\n        answer_list.append(dataset['answers'][index][index1])\n\n\n  new_df = {'question':question_list,'answers':answer_list}\n\n#   train_dataset = Dataset.from_dict(new_list)\n#   print('yes')\n#   dataset_dict = DatasetDict({\n#     \"train\": train_dataset\n# })\n\n  return new_df\n\ntrain_data = new_dataset(small_train_data)\nval_data = new_dataset(small_val_data)\ntrain_data_frame = Dataset.from_dict(train_data)\nval_data_frame = Dataset.from_dict(val_data)\n\n\ntrain_data_frame","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:26:50.058313Z","iopub.execute_input":"2024-05-19T18:26:50.059190Z","iopub.status.idle":"2024-05-19T18:26:50.168699Z","shell.execute_reply.started":"2024-05-19T18:26:50.059153Z","shell.execute_reply":"2024-05-19T18:26:50.167537Z"},"trusted":true},"execution_count":45,"outputs":[{"execution_count":45,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'answers'],\n    num_rows: 192\n})"},"metadata":{}}]},{"cell_type":"code","source":"val_data_frame","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:26:51.854879Z","iopub.execute_input":"2024-05-19T18:26:51.855213Z","iopub.status.idle":"2024-05-19T18:26:51.863238Z","shell.execute_reply.started":"2024-05-19T18:26:51.855189Z","shell.execute_reply":"2024-05-19T18:26:51.862134Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'answers'],\n    num_rows: 222\n})"},"metadata":{}}]},{"cell_type":"code","source":"# We prefix our tasks with \"answer the question\"\nprefix = \"Please answer this question: \"\n\n# Define the preprocessing function\n\ndef preprocess_function(examples):\n   \"\"\"Add prefix to the sentences, tokenize the text, and set the labels\"\"\"\n   # The \"inputs\" are the tokenized answer:\n   inputs = [prefix + doc for doc in examples[\"question\"]]\n   model_inputs = tokenizer(inputs, max_length=64, truncation=True)\n  \n   # The \"labels\" are the tokenized outputs:\n   labels = tokenizer(text_target=examples[\"answers\"], \n                      max_length=256,         \n                      truncation=True)\n\n   model_inputs[\"labels\"] = labels[\"input_ids\"]\n   return model_inputs","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:26:53.288216Z","iopub.execute_input":"2024-05-19T18:26:53.289117Z","iopub.status.idle":"2024-05-19T18:26:53.296377Z","shell.execute_reply.started":"2024-05-19T18:26:53.289085Z","shell.execute_reply":"2024-05-19T18:26:53.295181Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# Map the preprocessing function across our dataset\ntokenized_train_dataset = train_data_frame.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:26:56.879654Z","iopub.execute_input":"2024-05-19T18:26:56.880019Z","iopub.status.idle":"2024-05-19T18:26:57.160430Z","shell.execute_reply.started":"2024-05-19T18:26:56.879992Z","shell.execute_reply":"2024-05-19T18:26:57.159460Z"},"trusted":true},"execution_count":48,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/192 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"67a8d0e51a4142d7b9ae4ca33b7272ec"}},"metadata":{}}]},{"cell_type":"code","source":"# Map the preprocessing function across our dataset\ntokenized_val_dataset = val_data_frame.map(preprocess_function, batched=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:26:58.013769Z","iopub.execute_input":"2024-05-19T18:26:58.014137Z","iopub.status.idle":"2024-05-19T18:26:58.340571Z","shell.execute_reply.started":"2024-05-19T18:26:58.014108Z","shell.execute_reply":"2024-05-19T18:26:58.339489Z"},"trusted":true},"execution_count":49,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/222 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26bc29e5dc42416f8704e5d25e68502c"}},"metadata":{}}]},{"cell_type":"code","source":"nltk.download(\"punkt\", quiet=True)\nmetric = evaluate.load(\"rouge\")\n\nnltk.download(\"punkt\", quiet=True)\nmetric = evaluate.load(\"rouge\")\n\ndef compute_metrics(eval_preds):\n   preds, labels = eval_preds\n\n   # decode preds and labels\n   labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n   decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n   decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n   # rougeLSum expects newline after each sentence\n   decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n   decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n\n   result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n  \n   return result","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:28:46.640329Z","iopub.execute_input":"2024-05-19T18:28:46.640989Z","iopub.status.idle":"2024-05-19T18:28:47.211013Z","shell.execute_reply.started":"2024-05-19T18:28:46.640956Z","shell.execute_reply":"2024-05-19T18:28:47.210051Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"tokenized_train_dataset","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:28:49.257638Z","iopub.execute_input":"2024-05-19T18:28:49.258278Z","iopub.status.idle":"2024-05-19T18:28:49.265826Z","shell.execute_reply.started":"2024-05-19T18:28:49.258246Z","shell.execute_reply":"2024-05-19T18:28:49.264536Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['question', 'answers', 'input_ids', 'attention_mask', 'labels'],\n    num_rows: 192\n})"},"metadata":{}}]},{"cell_type":"code","source":"# Global Parameters\nL_RATE = 3e-4\nBATCH_SIZE = 8\nPER_DEVICE_EVAL_BATCH = 8\nWEIGHT_DECAY = 0.01\nSAVE_TOTAL_LIM = 3\nNUM_EPOCHS = 2\n\n# Set up training arguments\ntraining_args = Seq2SeqTrainingArguments(\n   output_dir=\"/kaggle/working/\",\n   evaluation_strategy=\"epoch\",\n   learning_rate=L_RATE,\n   per_device_train_batch_size=BATCH_SIZE,\n   per_device_eval_batch_size=PER_DEVICE_EVAL_BATCH,\n   weight_decay=WEIGHT_DECAY,\n   save_total_limit=SAVE_TOTAL_LIM,\n   num_train_epochs=NUM_EPOCHS,\n   predict_with_generate=True,\n   push_to_hub=False\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:28:51.835812Z","iopub.execute_input":"2024-05-19T18:28:51.836533Z","iopub.status.idle":"2024-05-19T18:28:51.872808Z","shell.execute_reply.started":"2024-05-19T18:28:51.836503Z","shell.execute_reply":"2024-05-19T18:28:51.871913Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stderr","text":"Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n","output_type":"stream"}]},{"cell_type":"code","source":"trainer = Seq2SeqTrainer(\n   model=model,\n   args=training_args,\n   train_dataset=tokenized_train_dataset,\n   eval_dataset=tokenized_val_dataset,\n   tokenizer=tokenizer,\n   data_collator=data_collator,\n   compute_metrics=compute_metrics\n)","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:28:55.353900Z","iopub.execute_input":"2024-05-19T18:28:55.354347Z","iopub.status.idle":"2024-05-19T18:28:55.371041Z","shell.execute_reply.started":"2024-05-19T18:28:55.354311Z","shell.execute_reply":"2024-05-19T18:28:55.370005Z"},"trusted":true},"execution_count":63,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"import os\nos.environ[\"WANDB_DISABLED\"] = 'true'","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:28:57.603169Z","iopub.execute_input":"2024-05-19T18:28:57.603538Z","iopub.status.idle":"2024-05-19T18:28:57.609956Z","shell.execute_reply.started":"2024-05-19T18:28:57.603510Z","shell.execute_reply":"2024-05-19T18:28:57.608405Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-05-19T18:28:59.096039Z","iopub.execute_input":"2024-05-19T18:28:59.096404Z","iopub.status.idle":"2024-05-19T18:29:51.065340Z","shell.execute_reply.started":"2024-05-19T18:28:59.096376Z","shell.execute_reply":"2024-05-19T18:29:51.064066Z"},"trusted":true},"execution_count":65,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='48' max='48' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [48/48 00:51, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>Rouge1</th>\n      <th>Rouge2</th>\n      <th>Rougel</th>\n      <th>Rougelsum</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>No log</td>\n      <td>3.675748</td>\n      <td>0.122770</td>\n      <td>0.016510</td>\n      <td>0.092955</td>\n      <td>0.109584</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>No log</td>\n      <td>3.576039</td>\n      <td>0.118485</td>\n      <td>0.016138</td>\n      <td>0.092712</td>\n      <td>0.106892</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1132: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n","output_type":"stream"},{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=48, training_loss=2.9712111155192056, metrics={'train_runtime': 51.4548, 'train_samples_per_second': 7.463, 'train_steps_per_second': 0.933, 'total_flos': 6520690360320.0, 'train_loss': 2.9712111155192056, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"!wandb.init() ","metadata":{"execution":{"iopub.status.busy":"2024-05-19T17:30:36.883967Z","iopub.execute_input":"2024-05-19T17:30:36.884248Z","iopub.status.idle":"2024-05-19T17:30:37.892737Z","shell.execute_reply.started":"2024-05-19T17:30:36.884224Z","shell.execute_reply":"2024-05-19T17:30:37.891596Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"/bin/bash: -c: line 1: syntax error: unexpected end of file\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}