{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Step1: Install and Import libraries**"
      ],
      "metadata": {
        "id": "FYbVnINIIJdi"
      },
      "id": "FYbVnINIIJdi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "16518d85",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:03:27.601297Z",
          "iopub.status.busy": "2024-05-21T15:03:27.600919Z",
          "iopub.status.idle": "2024-05-21T15:03:40.852789Z",
          "shell.execute_reply": "2024-05-21T15:03:40.851804Z"
        },
        "papermill": {
          "duration": 13.264125,
          "end_time": "2024-05-21T15:03:40.855278",
          "exception": false,
          "start_time": "2024-05-21T15:03:27.591153",
          "status": "completed"
        },
        "tags": [],
        "collapsed": true,
        "id": "16518d85",
        "outputId": "339ba159-1a7a-462d-f375-bef5bfd5bab9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\r\n",
            "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\r\n",
            "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\r\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\r\n",
            "Requirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\r\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\r\n",
            "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\r\n",
            "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\r\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\r\n",
            "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\r\n",
            "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\r\n",
            "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\r\n",
            "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\r\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\r\n",
            "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\r\n",
            "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\r\n",
            "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\r\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\r\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\r\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\r\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\r\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\r\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\r\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\r\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\r\n",
            "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\r\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\r\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\r\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\r\n",
            "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\r\n",
            "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\r\n",
            "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\r\n"
          ]
        }
      ],
      "source": [
        "!pip install -qq datasets\n",
        "!pip install -qq rouge-score datasets\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import BartForConditionalGeneration, BartTokenizer, Trainer, TrainingArguments, AdamW\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import Trainer, TrainingArguments\n",
        "import os\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Step 2: Data Loading**"
      ],
      "metadata": {
        "id": "rCn0WqGkIcN7"
      },
      "id": "rCn0WqGkIcN7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72bce7c1",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:03:57.692397Z",
          "iopub.status.busy": "2024-05-21T15:03:57.691845Z",
          "iopub.status.idle": "2024-05-21T15:04:31.412918Z",
          "shell.execute_reply": "2024-05-21T15:04:31.412006Z"
        },
        "papermill": {
          "duration": 33.732566,
          "end_time": "2024-05-21T15:04:31.414949",
          "exception": false,
          "start_time": "2024-05-21T15:03:57.682383",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "5c89e6a2ad544977b718ebd023fac69c",
            "52445afeeaff445a90a2f6f4ac7c32eb",
            "a4454c9385284df098c1f1ac1a577e8d",
            "a4b21751810941359b3d63672aa46b6f",
            "63c108fc01cb4d7fa8be2458bad5a85c",
            "0c5524e259a74120bb2d1db439533d83",
            "fe5df948f5f440cca7434a8b786a2216",
            "94dd32b3767445058ca207c8e158bdeb",
            "b715d91556584932a73a382b4aed1916",
            "2b26fef5adf54c7bb98cd9a03a5f7d53"
          ]
        },
        "collapsed": true,
        "id": "72bce7c1",
        "outputId": "88349a82-56b2-49e9-ef11-8dcdc3b793aa"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for eli5_category contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/eli5_category\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5c89e6a2ad544977b718ebd023fac69c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52445afeeaff445a90a2f6f4ac7c32eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading readme:   0%|          | 0.00/12.6k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4454c9385284df098c1f1ac1a577e8d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/62.3M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a4b21751810941359b3d63672aa46b6f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/5.00M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "63c108fc01cb4d7fa8be2458bad5a85c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.76M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0c5524e259a74120bb2d1db439533d83",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading data:   0%|          | 0.00/3.85M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fe5df948f5f440cca7434a8b786a2216",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/91772 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "94dd32b3767445058ca207c8e158bdeb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation1 split:   0%|          | 0/5446 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b715d91556584932a73a382b4aed1916",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating validation2 split:   0%|          | 0/2375 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2b26fef5adf54c7bb98cd9a03a5f7d53",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating test split:   0%|          | 0/5411 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n",
              "        num_rows: 91772\n",
              "    })\n",
              "    validation1: Dataset({\n",
              "        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n",
              "        num_rows: 5446\n",
              "    })\n",
              "    validation2: Dataset({\n",
              "        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n",
              "        num_rows: 2375\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['q_id', 'title', 'selftext', 'category', 'subreddit', 'answers', 'title_urls', 'selftext_urls'],\n",
              "        num_rows: 5411\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = load_dataset(\"eli5_category\")\n",
        "dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b07d36a7",
      "metadata": {
        "papermill": {
          "duration": 0.013705,
          "end_time": "2024-05-21T15:04:57.801663",
          "exception": false,
          "start_time": "2024-05-21T15:04:57.787958",
          "status": "completed"
        },
        "tags": [],
        "id": "b07d36a7"
      },
      "source": [
        "## 2-1 Prepare dataset to train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e983d443",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:04:57.830132Z",
          "iopub.status.busy": "2024-05-21T15:04:57.829789Z",
          "iopub.status.idle": "2024-05-21T15:04:57.836868Z",
          "shell.execute_reply": "2024-05-21T15:04:57.835972Z"
        },
        "papermill": {
          "duration": 0.023843,
          "end_time": "2024-05-21T15:04:57.838887",
          "exception": false,
          "start_time": "2024-05-21T15:04:57.815044",
          "status": "completed"
        },
        "tags": [],
        "id": "e983d443"
      },
      "outputs": [],
      "source": [
        "def organize_dataset(data):\n",
        "    questions = []\n",
        "    answers_list = []\n",
        "    scores_list = []\n",
        "\n",
        "    for item in data:\n",
        "        answers = item['answers']['text']\n",
        "        scores = item['answers'].get('score', [])\n",
        "\n",
        "        questions.append(item['title'])\n",
        "        answers_list.append(answers)\n",
        "        scores_list.append(scores)\n",
        "    return {\n",
        "        \"questions\": questions,\n",
        "        \"answers\": answers_list,\n",
        "        \"scores\": scores_list\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-2 Weighted_sampling"
      ],
      "metadata": {
        "id": "wNIojDAAMnL0"
      },
      "id": "wNIojDAAMnL0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "95b9d524",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:04:57.866079Z",
          "iopub.status.busy": "2024-05-21T15:04:57.865819Z",
          "iopub.status.idle": "2024-05-21T15:04:57.871447Z",
          "shell.execute_reply": "2024-05-21T15:04:57.870634Z"
        },
        "papermill": {
          "duration": 0.021485,
          "end_time": "2024-05-21T15:04:57.873308",
          "exception": false,
          "start_time": "2024-05-21T15:04:57.851823",
          "status": "completed"
        },
        "tags": [],
        "id": "95b9d524"
      },
      "outputs": [],
      "source": [
        "# Define weighted sampling function\n",
        "def weighted_sample(answers, scores, k=3):\n",
        "    k = min(k, len(answers))\n",
        "\n",
        "    if len(answers) == 0:\n",
        "        return []\n",
        "\n",
        "    total_score = sum(scores)\n",
        "    probabilities = [score / total_score for score in scores]\n",
        "    sampled_indices = np.random.choice(len(answers), size=k, replace=False, p=probabilities)\n",
        "    return [answers[i] for i in sampled_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0f81979a",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:04:57.899638Z",
          "iopub.status.busy": "2024-05-21T15:04:57.899364Z",
          "iopub.status.idle": "2024-05-21T15:04:57.906007Z",
          "shell.execute_reply": "2024-05-21T15:04:57.905299Z"
        },
        "papermill": {
          "duration": 0.021808,
          "end_time": "2024-05-21T15:04:57.907778",
          "exception": false,
          "start_time": "2024-05-21T15:04:57.885970",
          "status": "completed"
        },
        "tags": [],
        "id": "0f81979a"
      },
      "outputs": [],
      "source": [
        "# Prepare the dataset for training\n",
        "def prepare_dataset(data):\n",
        "    inputs = []\n",
        "    targets = []\n",
        "    for question, answers, scores in zip(data[\"questions\"], data[\"answers\"], data[\"scores\"]):\n",
        "\n",
        "        sampled_answers = weighted_sample(answers, scores)\n",
        "        combined_sampled_answers = \" \".join(sampled_answers)\n",
        "        input_text = f\"explain this question: {question} context: {combined_sampled_answers}\"\n",
        "        target_text = \" \".join(sampled_answers)\n",
        "        inputs.append(input_text)\n",
        "        targets.append(target_text)\n",
        "\n",
        "    return inputs, targets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2-3 Train-Validation Split"
      ],
      "metadata": {
        "id": "05KwirJqNMsU"
      },
      "id": "05KwirJqNMsU"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "260470f7",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:04:57.934217Z",
          "iopub.status.busy": "2024-05-21T15:04:57.933957Z",
          "iopub.status.idle": "2024-05-21T15:05:15.224158Z",
          "shell.execute_reply": "2024-05-21T15:05:15.223329Z"
        },
        "papermill": {
          "duration": 17.305889,
          "end_time": "2024-05-21T15:05:15.226481",
          "exception": false,
          "start_time": "2024-05-21T15:04:57.920592",
          "status": "completed"
        },
        "tags": [],
        "id": "260470f7"
      },
      "outputs": [],
      "source": [
        "train_data = organize_dataset(dataset[\"train\"])\n",
        "validation_data = organize_dataset(dataset[\"validation1\"])\n",
        "small_train_data = {key: value[:10000] for key, value in train_data.items()}\n",
        "small_validation_data = {key: value[:500] for key, value in validation_data.items()}\n",
        "train_inputs, train_targets = prepare_dataset(small_train_data)\n",
        "validation_inputs, validation_targets = prepare_dataset(small_validation_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1600793",
      "metadata": {
        "papermill": {
          "duration": 0.012845,
          "end_time": "2024-05-21T15:05:15.252453",
          "exception": false,
          "start_time": "2024-05-21T15:05:15.239608",
          "status": "completed"
        },
        "tags": [],
        "id": "c1600793"
      },
      "source": [
        "# **Step 3: Tokenization and DataLoader**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:04:31.543675Z",
          "iopub.status.busy": "2024-05-21T15:04:31.543367Z",
          "iopub.status.idle": "2024-05-21T15:04:40.949850Z",
          "shell.execute_reply": "2024-05-21T15:04:40.949000Z"
        },
        "papermill": {
          "duration": 9.420148,
          "end_time": "2024-05-21T15:04:40.952065",
          "exception": false,
          "start_time": "2024-05-21T15:04:31.531917",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "5655731ad7794c1281a910509dbf9cab",
            "0bde695167774aa7a5e9c509839d55e0",
            "e29a8191b0f7425aa200d89403bd234c",
            "1a8bb8f952424105a2f6fe75285148b7",
            "8a0790dc30914f829f64c912d96af8aa",
            "4b7e974907a543f9815669ede8221a4b"
          ]
        },
        "id": "c705fecf",
        "outputId": "98ff7af4-ad33-46ab-d660-7c893e13c358"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5655731ad7794c1281a910509dbf9cab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bde695167774aa7a5e9c509839d55e0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e29a8191b0f7425aa200d89403bd234c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1a8bb8f952424105a2f6fe75285148b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8a0790dc30914f829f64c912d96af8aa",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/1.63k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4b7e974907a543f9815669ede8221a4b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.02G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n"
          ]
        }
      ],
      "source": [
        "tokenizer = BartTokenizer.from_pretrained('facebook/bart-large')\n",
        "model = BartForConditionalGeneration.from_pretrained('facebook/bart-large').to(device)"
      ],
      "id": "c705fecf"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-1 Add Special tokens"
      ],
      "metadata": {
        "id": "Y0v7gHpRNvVL"
      },
      "id": "Y0v7gHpRNvVL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "20ae6ce6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:05:15.279044Z",
          "iopub.status.busy": "2024-05-21T15:05:15.278764Z",
          "iopub.status.idle": "2024-05-21T15:05:15.350192Z",
          "shell.execute_reply": "2024-05-21T15:05:15.349324Z"
        },
        "papermill": {
          "duration": 0.086837,
          "end_time": "2024-05-21T15:05:15.352133",
          "exception": false,
          "start_time": "2024-05-21T15:05:15.265296",
          "status": "completed"
        },
        "tags": [],
        "id": "20ae6ce6",
        "outputId": "fde4052e-e9c6-4f79-a14e-a828a9b215f4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Embedding(50267, 1024)"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "special_tokens_dict = {'additional_special_tokens': ['<ans_start>', '<ans_end>']}\n",
        "num_added_toks = tokenizer.add_special_tokens(special_tokens_dict)\n",
        "model.resize_token_embeddings(len(tokenizer))  # Adjust model's token embeddings to accommodate new tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-2 Tokenization"
      ],
      "metadata": {
        "id": "BLoH7MSJN9NL"
      },
      "id": "BLoH7MSJN9NL"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "888f4d70",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:05:15.380126Z",
          "iopub.status.busy": "2024-05-21T15:05:15.379825Z",
          "iopub.status.idle": "2024-05-21T15:05:15.388678Z",
          "shell.execute_reply": "2024-05-21T15:05:15.387896Z"
        },
        "papermill": {
          "duration": 0.024974,
          "end_time": "2024-05-21T15:05:15.390530",
          "exception": false,
          "start_time": "2024-05-21T15:05:15.365556",
          "status": "completed"
        },
        "tags": [],
        "id": "888f4d70"
      },
      "outputs": [],
      "source": [
        "def tokenize_with_encode_plus(inputs, targets, tokenizer, max_length=512):\n",
        "\n",
        "    encodings = {'input_ids': [], 'attention_mask': [], 'labels': []}\n",
        "\n",
        "    # Adding special tokens manually for clarity\n",
        "    ans_start_token = \"<ans_start>\"\n",
        "    ans_end_token = \"<ans_end>\"\n",
        "\n",
        "    for input_text, target_text in zip(inputs, targets):\n",
        "        # Prepend and append the special tokens to the target text\n",
        "        modified_target_text = f\"{ans_start_token} {target_text} {ans_end_token}\"\n",
        "\n",
        "        input_tokens = tokenizer.encode_plus(\n",
        "            input_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        target_tokens = tokenizer.encode_plus(\n",
        "            modified_target_text,\n",
        "            add_special_tokens=True,  # This will also include the tokenizer's default special tokens\n",
        "            max_length=max_length,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "\n",
        "        encodings['input_ids'].append(input_tokens['input_ids'])\n",
        "        encodings['attention_mask'].append(input_tokens['attention_mask'])\n",
        "        encodings['labels'].append(target_tokens['input_ids'])\n",
        "\n",
        "    # Concatenate lists of tensors into a single tensor\n",
        "    encodings['input_ids'] = torch.cat(encodings['input_ids'], dim=0)\n",
        "    encodings['attention_mask'] = torch.cat(encodings['attention_mask'], dim=0)\n",
        "    encodings['labels'] = torch.cat(encodings['labels'], dim=0)\n",
        "\n",
        "    return encodings\n",
        "\n",
        "    if len(encodings['input_ids']) == 1:  # Example print out for the first batch\n",
        "        print(\"Example of tokenized input:\", tokenizer.convert_ids_to_tokens(input_tokens['input_ids'][0]))\n",
        "        print(\"Example of tokenized target:\", tokenizer.convert_ids_to_tokens(target_tokens['input_ids'][0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3-3 DataLoader"
      ],
      "metadata": {
        "id": "h7wu5cfxO7e_"
      },
      "id": "h7wu5cfxO7e_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f9730da4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:05:15.417239Z",
          "iopub.status.busy": "2024-05-21T15:05:15.416975Z",
          "iopub.status.idle": "2024-05-21T15:05:15.422575Z",
          "shell.execute_reply": "2024-05-21T15:05:15.421778Z"
        },
        "papermill": {
          "duration": 0.021172,
          "end_time": "2024-05-21T15:05:15.424445",
          "exception": false,
          "start_time": "2024-05-21T15:05:15.403273",
          "status": "completed"
        },
        "tags": [],
        "id": "f9730da4"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings):\n",
        "        self.encodings = encodings\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.encodings['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ccb422c4",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:05:15.451642Z",
          "iopub.status.busy": "2024-05-21T15:05:15.451392Z",
          "iopub.status.idle": "2024-05-21T15:06:21.151258Z",
          "shell.execute_reply": "2024-05-21T15:06:21.150245Z"
        },
        "papermill": {
          "duration": 65.716337,
          "end_time": "2024-05-21T15:06:21.153901",
          "exception": false,
          "start_time": "2024-05-21T15:05:15.437564",
          "status": "completed"
        },
        "tags": [],
        "id": "ccb422c4"
      },
      "outputs": [],
      "source": [
        "def prepare_dataloader(inputs, targets, tokenizer, batch_size=8, max_length=512):\n",
        "    encodings = tokenize_with_encode_plus(inputs, targets, tokenizer, max_length)\n",
        "    dataset = CustomDataset(encodings)\n",
        "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "    return dataloader\n",
        "\n",
        "\n",
        "\n",
        "train_dataloader = prepare_dataloader(train_inputs, train_targets, tokenizer, batch_size=2)\n",
        "validation_dataloader = prepare_dataloader(validation_inputs, validation_targets, tokenizer, batch_size=2)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_dataloader(dataloader):\n",
        "    for i, batch in enumerate(dataloader):\n",
        "        print(f\"Batch {i + 1}\")\n",
        "        print(\"Input IDs:\", batch['input_ids'].shape)\n",
        "        print(batch['input_ids'])\n",
        "        print(\"Attention Mask:\", batch['attention_mask'].shape)\n",
        "        print(batch['attention_mask'])\n",
        "        print(\"Labels:\", batch['labels'].shape)\n",
        "        print(batch['labels'])\n",
        "        print(\"Input Text Example:\", tokenizer.decode(batch['input_ids'][0]))\n",
        "        print(\"Label Text Example:\", tokenizer.decode(batch['labels'][0]))\n",
        "        if i >= 1:\n",
        "            break\n",
        "\n",
        "\n",
        "test_dataloader(train_dataloader)"
      ],
      "metadata": {
        "id": "1DwTuaviOVWl"
      },
      "id": "1DwTuaviOVWl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Train and Validate**"
      ],
      "metadata": {
        "id": "JwZXyXQoPdhu"
      },
      "id": "JwZXyXQoPdhu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4-1 Load Rouge"
      ],
      "metadata": {
        "id": "N1nujCx9gAae"
      },
      "id": "N1nujCx9gAae"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c2311ba",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:06:21.248296Z",
          "iopub.status.busy": "2024-05-21T15:06:21.247595Z",
          "iopub.status.idle": "2024-05-21T15:06:22.024012Z",
          "shell.execute_reply": "2024-05-21T15:06:22.023250Z"
        },
        "papermill": {
          "duration": 0.792145,
          "end_time": "2024-05-21T15:06:22.026307",
          "exception": false,
          "start_time": "2024-05-21T15:06:21.234162",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "referenced_widgets": [
            "1ec4da46f2f54630aa9ed45de9e87097"
          ]
        },
        "id": "2c2311ba",
        "outputId": "1cc74d40-0c25-43a5-f447-22374a48f5c0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_25/138901168.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  rouge = load_metric('rouge')\n",
            "/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ec4da46f2f54630aa9ed45de9e87097",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/2.17k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "rouge = load_metric('rouge')\n",
        "\n",
        "def compute_rouge(predictions, references):\n",
        "    return rouge.compute(predictions=predictions, references=references)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4-2 Train and Validate"
      ],
      "metadata": {
        "id": "OhW_mX3_gHEf"
      },
      "id": "OhW_mX3_gHEf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c808b3a6",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:06:22.055052Z",
          "iopub.status.busy": "2024-05-21T15:06:22.054752Z",
          "iopub.status.idle": "2024-05-21T15:06:22.068743Z",
          "shell.execute_reply": "2024-05-21T15:06:22.067923Z"
        },
        "papermill": {
          "duration": 0.030152,
          "end_time": "2024-05-21T15:06:22.070531",
          "exception": false,
          "start_time": "2024-05-21T15:06:22.040379",
          "status": "completed"
        },
        "tags": [],
        "id": "c808b3a6"
      },
      "outputs": [],
      "source": [
        "def train_and_validate(model, train_dataloader, validation_dataloader, tokenizer, optimizer, num_epochs=3, device='cuda', checkpoint_dir='checkpoints'):\n",
        "    model.to(device)\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    rouge = load_metric('rouge')\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        total_val_loss = 0\n",
        "\n",
        "        # Training phase\n",
        "        for batch in tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}\"):\n",
        "            optimizer.zero_grad()\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        # Checkpointing after each epoch\n",
        "        checkpoint_path = os.path.join(checkpoint_dir, f'checkpoint_epoch_{epoch+1}.pt')\n",
        "        torch.save(model.state_dict(), checkpoint_path)\n",
        "\n",
        "        # Validation phase\n",
        "        model.eval()\n",
        "        predictions = []\n",
        "        references = []\n",
        "        with torch.no_grad():\n",
        "            for batch in tqdm(validation_dataloader, desc=f\"Validation Epoch {epoch + 1}\"):\n",
        "                input_ids = batch['input_ids'].to(device)\n",
        "                attention_mask = batch['attention_mask'].to(device)\n",
        "                labels = batch['labels'].to(device)\n",
        "\n",
        "                outputs = model.generate(input_ids, attention_mask=attention_mask, max_length=512, num_beams=5, early_stopping=True)\n",
        "                decoded_preds = [tokenizer.decode(gid, skip_special_tokens=True) for gid in outputs]\n",
        "                decoded_labels = [tokenizer.decode(lid, skip_special_tokens=True) for lid in labels.cpu().numpy()]\n",
        "\n",
        "                predictions.extend(decoded_preds)\n",
        "                references.extend(decoded_labels)\n",
        "\n",
        "#                 val_loss = outputs.loss.mean().item()  # Assumes 'loss' is returned in generate; adjust as needed\n",
        "#                 total_val_loss += val_loss\n",
        "\n",
        "\n",
        "        rouge_results = rouge.compute(predictions=predictions, references=references)\n",
        "\n",
        "        # Extract a few needed results from ROUGE\n",
        "        rouge1 = rouge_results['rouge1'].mid.fmeasure\n",
        "        rouge2 = rouge_results['rouge2'].mid.fmeasure\n",
        "        rougeL = rouge_results['rougeL'].mid.fmeasure\n",
        "\n",
        "\n",
        "        results.append({\n",
        "            \"Epoch\": epoch + 1,\n",
        "            \"Training Loss\": total_loss / len(train_dataloader),\n",
        "            \"Validation Loss\": total_val_loss / len(validation_dataloader),\n",
        "            \"ROUGE-1\": rouge1,\n",
        "            \"ROUGE-2\": rouge2,\n",
        "            \"ROUGE-L\": rougeL\n",
        "        })\n",
        "\n",
        "\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(results_df)\n",
        "\n",
        "    return model\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6babeba3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:06:22.098387Z",
          "iopub.status.busy": "2024-05-21T15:06:22.098116Z",
          "iopub.status.idle": "2024-05-21T21:59:45.889552Z",
          "shell.execute_reply": "2024-05-21T21:59:45.888594Z"
        },
        "papermill": {
          "duration": 24805.115372,
          "end_time": "2024-05-21T21:59:47.199311",
          "exception": false,
          "start_time": "2024-05-21T15:06:22.083939",
          "status": "completed"
        },
        "tags": [],
        "id": "6babeba3",
        "outputId": "9eeb40c8-fa61-4024-bd07-d0f494a8cc14"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:457: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "/opt/conda/lib/python3.10/site-packages/datasets/load.py:756: FutureWarning: The repository for rouge contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.18.0/metrics/rouge/rouge.py\n",
            "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
            "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
            "  warnings.warn(\n",
            "Training Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [1:21:25<00:00,  1.02it/s]\n",
            "Validation Epoch 1: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [56:15<00:00, 13.50s/it]\n",
            "Training Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [1:21:21<00:00,  1.02it/s]\n",
            "Validation Epoch 2: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [56:13<00:00, 13.50s/it]\n",
            "Training Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5000/5000 [1:21:24<00:00,  1.02it/s]\n",
            "Validation Epoch 3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 250/250 [55:31<00:00, 13.33s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   Epoch  Training Loss  Validation Loss   ROUGE-1   ROUGE-2   ROUGE-L\n",
            "0      1       3.122547              0.0  0.247136  0.003855  0.092680\n",
            "1      2       3.741816              0.0  0.246812  0.001977  0.093557\n",
            "2      3       3.584353              0.0  0.255596  0.002633  0.094907\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "BartForConditionalGeneration(\n",
              "  (model): BartModel(\n",
              "    (shared): Embedding(50267, 1024)\n",
              "    (encoder): BartEncoder(\n",
              "      (embed_tokens): Embedding(50267, 1024)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartEncoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (activation_fn): GELUActivation()\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "    (decoder): BartDecoder(\n",
              "      (embed_tokens): Embedding(50267, 1024)\n",
              "      (embed_positions): BartLearnedPositionalEmbedding(1026, 1024)\n",
              "      (layers): ModuleList(\n",
              "        (0-11): 12 x BartDecoderLayer(\n",
              "          (self_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (activation_fn): GELUActivation()\n",
              "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (encoder_attn): BartSdpaAttention(\n",
              "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "          )\n",
              "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (layernorm_embedding): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "    )\n",
              "  )\n",
              "  (lm_head): Linear(in_features=1024, out_features=50267, bias=False)\n",
              ")"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
        "\n",
        "train_and_validate(model, train_dataloader, validation_dataloader, tokenizer, optimizer, num_epochs=3, device='cuda', checkpoint_dir='checkpoints')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 5: Test Model**"
      ],
      "metadata": {
        "id": "V76RbJ0JgW_6"
      },
      "id": "V76RbJ0JgW_6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73b8d81d",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T15:06:21.213787Z",
          "iopub.status.busy": "2024-05-21T15:06:21.213495Z",
          "iopub.status.idle": "2024-05-21T15:06:21.219618Z",
          "shell.execute_reply": "2024-05-21T15:06:21.218756Z"
        },
        "papermill": {
          "duration": 0.02171,
          "end_time": "2024-05-21T15:06:21.221519",
          "exception": false,
          "start_time": "2024-05-21T15:06:21.199809",
          "status": "completed"
        },
        "tags": [],
        "id": "73b8d81d"
      },
      "outputs": [],
      "source": [
        "def generate_answers(model, tokenizer, questions, max_length=512, num_beams=5):\n",
        "    model.eval()\n",
        "    generated_answers = []\n",
        "\n",
        "    for question in questions:\n",
        "        inputs = tokenizer.encode_plus(question, return_tensors=\"pt\", max_length=max_length, truncation=True, padding=\"max_length\", add_special_tokens=True).to(device)\n",
        "        outputs = model.generate(inputs['input_ids'], attention_mask=inputs['attention_mask'], max_length=max_length, num_beams=num_beams, early_stopping=True)\n",
        "        generated_answer = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        generated_answers.append(generated_answer)\n",
        "\n",
        "    return generated_answers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eeedd5d3",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T22:00:03.468162Z",
          "iopub.status.busy": "2024-05-21T22:00:03.467806Z",
          "iopub.status.idle": "2024-05-21T22:07:55.233469Z",
          "shell.execute_reply": "2024-05-21T22:07:55.232508Z"
        },
        "papermill": {
          "duration": 474.446249,
          "end_time": "2024-05-21T22:07:56.618417",
          "exception": false,
          "start_time": "2024-05-21T22:00:02.172168",
          "status": "completed"
        },
        "tags": [],
        "id": "eeedd5d3",
        "outputId": "541410bc-3e0c-48f8-e8c3-ebea555ede7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: explain this question:why does stretching feel good?\n",
            "Predicted Answer:  It It The The They They Because Because There There is is I I When When the the's's You You Your Your are are a a of of This This,, A A In In you you it it Yes Yes If If't't We We Well Well That That Some Some to to.. don don have have Basically Basically can can Generally Generally What What think think Not Not Most Most not not in in Humans Humans No No \" \" they they Its Its Think Think that that Water Water body body People People For For So So do do Our Our're're has has One One As As My My > > doesn doesn First First Usually Usually your your and and'm'm actually actually because because Many Many Sound Sound Two Two an an Blood Blood Part Part air air Imagine Imagine question question water water To To Both Both Actually Actually From From isn\n"
          ]
        }
      ],
      "source": [
        "test_data = organize_dataset(dataset[\"validation2\"])\n",
        "small_test_data = {key: value[:2] for key, value in test_data.items()}\n",
        "q = small_test_data['questions'][0]\n",
        "query = f'explain this question:{q}'\n",
        "sample_answers = generate_answers(model, tokenizer, query , max_length=512, num_beams=5)\n",
        "predicted_answer = sample_answers[0]\n",
        "print(f\"Question: {query}\")\n",
        "print(f\"Predicted Answer: {predicted_answer}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 6: Save the Model**"
      ],
      "metadata": {
        "id": "WwAT18BjgRII"
      },
      "id": "WwAT18BjgRII"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4609fc48",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-05-21T21:59:57.959480Z",
          "iopub.status.busy": "2024-05-21T21:59:57.958590Z",
          "iopub.status.idle": "2024-05-21T22:00:00.861492Z",
          "shell.execute_reply": "2024-05-21T22:00:00.860529Z"
        },
        "papermill": {
          "duration": 4.199976,
          "end_time": "2024-05-21T22:00:00.863689",
          "exception": false,
          "start_time": "2024-05-21T21:59:56.663713",
          "status": "completed"
        },
        "tags": [],
        "id": "4609fc48",
        "outputId": "25f0687c-d004-4978-d1c7-a70e371677d3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
            "Non-default generation parameters: {'early_stopping': True, 'num_beams': 4, 'no_repeat_ngram_size': 3, 'forced_bos_token_id': 0, 'forced_eos_token_id': 2}\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('/kaggle/working/my_bart_model/tokenizer_config.json',\n",
              " '/kaggle/working/my_bart_model/special_tokens_map.json',\n",
              " '/kaggle/working/my_bart_model/vocab.json',\n",
              " '/kaggle/working/my_bart_model/merges.txt',\n",
              " '/kaggle/working/my_bart_model/added_tokens.json')"
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.save_pretrained('/kaggle/working/my_bart_model')\n",
        "tokenizer.save_pretrained('/kaggle/working/my_bart_model')"
      ]
    }
  ],
  "metadata": {
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [],
      "dockerImageVersionId": 30699,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 25496.444876,
      "end_time": "2024-05-21T22:08:20.897258",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2024-05-21T15:03:24.452382",
      "version": "2.5.0"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FYbVnINIIJdi",
        "rCn0WqGkIcN7",
        "b07d36a7",
        "wNIojDAAMnL0",
        "05KwirJqNMsU",
        "c1600793",
        "JwZXyXQoPdhu",
        "V76RbJ0JgW_6",
        "WwAT18BjgRII"
      ]
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}